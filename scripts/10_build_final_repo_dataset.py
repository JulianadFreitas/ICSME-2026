"""
build_final_repo_dataset.py

Build a final per-repository CSV dataset from snapshot JSON files generated by
extract_repo_features_and_snapshots.py.

Inputs:
  1) out/repos/github_repos_unique.csv
     Expected columns (auto-detected):
       - full_name OR full_repo_name OR repo_full_name  (e.g., owner/repo)
       - distros OR distros_present (e.g., "humble;jazzy" or "['humble','jazzy']")
  2) data/ros_robotics_data/<owner>__<repo>/*.json

Output:
  - out/final_repo_dataset.csv
"""

import os
import csv
import json
import re
from typing import Any, Dict, Optional, Tuple, List


# =========================
# CONFIG
# =========================
REPOS_CSV = "out/repos/github_repos_unique.csv"
DATA_ROOT = "data/ros_robotics_data"
OUT_CSV = "out/final_repo_dataset.csv"


# =========================
# JSON helpers
# =========================
def safe_read_json(path: str) -> Optional[Any]:
    try:
        if not os.path.exists(path) or os.path.getsize(path) == 0:
            return None
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def is_snapshot(obj: Any) -> bool:
    return isinstance(obj, dict) and "_meta" in obj and "data" in obj

def snapshot_data(obj: Any) -> Any:
    if is_snapshot(obj):
        return obj.get("data")
    return obj

def read_snapshot_file(repo_dir: str, filename: str) -> Any:
    obj = safe_read_json(os.path.join(repo_dir, filename))
    if obj is None:
        return None
    return snapshot_data(obj)


# =========================
# Parsing / normalization
# =========================
def parse_owner_repo(full_name: str) -> Tuple[Optional[str], Optional[str]]:
    if not full_name or "/" not in full_name:
        return None, None
    owner, repo = full_name.split("/", 1)
    owner = owner.strip()
    repo = repo.strip()
    if not owner or not repo:
        return None, None
    return owner, repo

def parse_distros_field(raw: Any) -> str:
    """
    Normalize distros field into a semicolon-separated string, e.g. "humble;jazzy;kilted".
    Accepts:
      - "humble;jazzy"
      - "['humble', 'jazzy']"
      - "humble, jazzy"
      - list ["humble", "jazzy"]
    """
    if raw is None:
        return ""

    if isinstance(raw, list):
        vals = [str(x).strip() for x in raw if str(x).strip()]
        vals = sorted(set(vals))
        return ";".join(vals)

    s = str(raw).strip()
    if not s:
        return ""

    # Try to parse python-like list: ['humble','jazzy']
    if (s.startswith("[") and s.endswith("]")) or (s.startswith("(") and s.endswith(")")):
        inner = s[1:-1].strip()
        # split by commas, strip quotes/spaces
        parts = [p.strip().strip("'").strip('"') for p in inner.split(",")]
        parts = [p for p in parts if p]
        parts = sorted(set(parts))
        return ";".join(parts)

    # split by ; or , if present
    if ";" in s:
        parts = [p.strip() for p in s.split(";")]
    elif "," in s:
        parts = [p.strip() for p in s.split(",")]
    else:
        parts = [s]

    parts = [p for p in parts if p]
    parts = sorted(set(parts))
    return ";".join(parts)

def topics_to_string(topics: Any) -> str:
    if topics is None:
        return ""
    if isinstance(topics, list):
        vals = [str(x).strip() for x in topics if str(x).strip()]
        return ";".join(vals)
    s = str(topics).strip()
    return s

def dominant_language(languages_obj: Any) -> str:
    """
    languages.json typically is a dict: {"Python": 12345, "C++": 6789}
    Return the language with the max bytes.
    """
    if not isinstance(languages_obj, dict) or not languages_obj:
        return ""
    # values are bytes
    best = max(languages_obj.items(), key=lambda kv: kv[1] if isinstance(kv[1], (int, float)) else -1)
    return str(best[0])

def all_languages_string(languages_obj: Any) -> str:
    if not isinstance(languages_obj, dict) or not languages_obj:
        return ""
    # sort by bytes desc
    items = [(k, v) for k, v in languages_obj.items() if isinstance(v, (int, float))]
    items.sort(key=lambda kv: kv[1], reverse=True)
    return ";".join([k for k, _ in items])

def bool_from_has(obj: Any, key: str) -> bool:
    if not isinstance(obj, dict):
        return False
    return bool(obj.get(key))

def bool_found(obj: Any) -> bool:
    if not isinstance(obj, dict):
        return False
    # used by contributing/code_of_conduct
    if "found" in obj:
        return bool(obj.get("found"))
    # used by readme
    if "download_url" in obj:
        return bool(obj.get("download_url"))
    return False

def license_string(license_json: Any, general_info: Any) -> str:
    if isinstance(license_json, dict):
        spdx = (license_json.get("spdx_id") or "").strip() if isinstance(license_json.get("spdx_id"), str) else ""
        name = (license_json.get("name") or "").strip() if isinstance(license_json.get("name"), str) else ""
        if spdx and spdx != "NOASSERTION":
            return spdx
        if name:
            return name

    if isinstance(general_info, dict):
        lic = general_info.get("license")
        if isinstance(lic, str):
            return lic.strip()

    return ""


# =========================
# Load repos list (unique CSV)
# =========================
def load_repos_csv(path: str) -> List[Dict[str, Any]]:
    if not os.path.exists(path):
        raise FileNotFoundError(f"Missing repos CSV: {path}")

    with open(path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        return list(reader)

def detect_full_name_key(row: Dict[str, Any]) -> Optional[str]:
    for k in ("full_name", "full_repo_name", "repo_full_name"):
        if k in row and row.get(k):
            return k
    return None

def detect_distros_key(row: Dict[str, Any]) -> Optional[str]:
    for k in ("distros_present", "distros"):
        if k in row:
            return k
    return None


# =========================
# Main builder
# =========================
def build_row(owner: str, repo: str, distros_present: str) -> Dict[str, Any]:
    repo_dir = os.path.join(DATA_ROOT, f"{owner}__{repo}")

    general_info = read_snapshot_file(repo_dir, "general_info.json") or {}
    readme = read_snapshot_file(repo_dir, "readme.json") or {}
    contributing = read_snapshot_file(repo_dir, "contributing.json") or {}
    coc = read_snapshot_file(repo_dir, "code_of_conduct.json") or {}
    issue_template = read_snapshot_file(repo_dir, "issue_template.json") or {}
    pr_template = read_snapshot_file(repo_dir, "pr_template.json") or {}
    labels_json = read_snapshot_file(repo_dir, "labels.json") or {}
    owner_info = read_snapshot_file(repo_dir, "owner_info.json") or {}
    first_commits = read_snapshot_file(repo_dir, "first_commits_by_author.json") or []
    contributors = read_snapshot_file(repo_dir, "contributors.json") or []
    commits = read_snapshot_file(repo_dir, "commits.json") or []
    license_json = read_snapshot_file(repo_dir, "license.json") or {}
    languages_json = read_snapshot_file(repo_dir, "languages.json") or {}

    # contributors_count
    contributors_count = len(contributors) if isinstance(contributors, list) else 0
    
    # commits_count
    commits_count = len(commits) if isinstance(commits, list) else 0

    # languages
    languages = all_languages_string(languages_json)

    # topics
    topics_str = topics_to_string(general_info.get("topics"))

    # license
    license_str = license_string(license_json, general_info)

    # base fields
    full_name = (general_info.get("full_name") or f"{owner}/{repo}").strip()
    html_url = (general_info.get("html_url") or f"https://github.com/{owner}/{repo}").strip()
    description = general_info.get("description") or ""

    # numeric
    size = general_info.get("size") or 0
    stargazers_count = general_info.get("stargazers_count") or 0
    forks_count = general_info.get("forks_count") or 0
    open_issues_count = general_info.get("open_issues_count") or 0
    subscribers_count = general_info.get("subscribers_count") or 0
    watchers_count = general_info.get("watchers_count") or 0

    # has_ flags (semantic)
    has_readme = bool_found(readme)
    has_contributing = bool_found(contributing)
    has_code_of_conduct = bool_found(coc)
    has_issue_template = bool_from_has(issue_template, "has_issue_template")
    has_pr_template = bool_from_has(pr_template, "has_pr_template")
    
    # newcomer labels
    has_newcomer_labels = bool_from_has(labels_json, "has_newcomer_labels")
    found_newcomer_labels = []
    if isinstance(labels_json, dict) and "found_newcomer_labels" in labels_json:
        found_newcomer_labels = labels_json.get("found_newcomer_labels", [])
        if isinstance(found_newcomer_labels, list):
            found_newcomer_labels = ";".join(found_newcomer_labels)
        else:
            found_newcomer_labels = ""
    
    # owner_type (Organization or User)
    owner_type = ""
    if isinstance(owner_info, dict):
        owner_type = owner_info.get("type", "")
    
    # first commit metrics
    first_contributor_date = ""
    first_commit_files_changed = 0
    first_commit_additions = 0
    first_commit_deletions = 0
    first_commit_type = ""
    
    if isinstance(first_commits, list) and len(first_commits) > 0:
        # Find the earliest commit overall
        try:
            earliest = min(first_commits, key=lambda x: x.get("date", ""))
            first_contributor_date = earliest.get("date", "")
            first_commit_files_changed = earliest.get("files_changed", 0)
            first_commit_additions = earliest.get("additions", 0)
            first_commit_deletions = earliest.get("deletions", 0)
            first_commit_type = earliest.get("commit_type", "")
        except:
            pass

    return {
        "Name": repo,
        "Owner": owner,
        "Description": description,
        "GitHub URL": html_url,
        "Repository Size": size,
        "Number of stars": stargazers_count,
        "Number of forks": forks_count,
        "Number of open issues": open_issues_count,
        "List of topics": topics_str,
        "License": license_str,
        "has_readme": has_readme,
        "has_contributing": has_contributing,
        "has_code_of_conduct": has_code_of_conduct,
        "has_pr_template": has_pr_template,
        "has_issue_template": has_issue_template,
        "has_newcomer_labels": has_newcomer_labels,
        "found_newcomer_labels": found_newcomer_labels,
        "contributors_count": contributors_count,
        "commits_count": commits_count,
        "first_contributor_date": first_contributor_date,
        "first_commit_files_changed": first_commit_files_changed,
        "first_commit_additions": first_commit_additions,
        "first_commit_deletions": first_commit_deletions,
        "first_commit_type": first_commit_type,
        "owner_type": owner_type,
        "size": size,
        "subscribers_count": subscribers_count,
        "watchers_count": watchers_count,
        "languages": languages,
        "full_name": full_name,
        "distros_present": distros_present,
    }

def main():
    rows = load_repos_csv(REPOS_CSV)
    if not rows:
        raise RuntimeError("Repos CSV is empty.")

    full_name_key = detect_full_name_key(rows[0])
    if not full_name_key:
        raise RuntimeError(
            f"Cannot find repo full_name column in {REPOS_CSV}. "
            "Expected one of: full_name, full_repo_name, repo_full_name"
        )

    distros_key = detect_distros_key(rows[0])

    out_rows: List[Dict[str, Any]] = []
    skipped = 0

    for i, row in enumerate(rows, start=1):
        full_name = (row.get(full_name_key) or "").strip()
        owner, repo = parse_owner_repo(full_name)
        if not owner or not repo:
            skipped += 1
            continue

        distros_present = ""
        if distros_key:
            distros_present = parse_distros_field(row.get(distros_key))

        built = build_row(owner, repo, distros_present)
        out_rows.append(built)

    os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)

    fieldnames = [
        "Name", "Owner", "Description", "GitHub URL",
        "Repository Size", "Number of stars", "Number of forks", "Number of open issues",
        "List of topics", "License",
        "has_readme", "has_contributing", "has_code_of_conduct", "has_pr_template", "has_issue_template",
        "has_newcomer_labels", "found_newcomer_labels",
        "contributors_count", "commits_count",
        "first_contributor_date", "first_commit_files_changed", "first_commit_additions", "first_commit_deletions", "first_commit_type",
        "owner_type",
        "size", "subscribers_count", "watchers_count",
        "languages",
        "full_name", "distros_present",
    ]

    with open(OUT_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for r in out_rows:
            writer.writerow(r)

    print(f"[OK] Wrote: {OUT_CSV} rows={len(out_rows)} skipped={skipped}")

if __name__ == "__main__":
    main()
